---
layout: post
title:  "C++并发编程"
---
《C++并发编程实战》的读书笔记  
之前看过一遍，可惜没留下什么印象，发现还是笔记有用，主要是辅助记忆的作用，敲一遍会深刻不少。诸君，勿谓言之不预也!  
## 2.线程管控
### 2.1 线程管控  
**发起线程**:任何可调用类型都可以std::thread  
启动线程后，要在thread析构前决定`join`或者`detach`，否则会调用`terminate`终止整个程序.使用`detach`要注意局部变量，指针和引用的使用，因为其可能会运行在thread析构之后。  
`joinable`函数可以检测线程是否可联结。  
### 2.2 向线程函数传递参数
向线程添加参数即可。因为线程内部具有存储空间，所以参数会先复制到线程中，然后以右值形式传递给线程中的函数。  
如果线程函数使用引用方式，一般来说会报错，因为右值无法引用，可以使用`std::ref`函数来获取相应引用。  
如果调用类里面的成员函数，需要传递成员函数指针和对象指针  

  
### 2.3 移交线程归属权
线程只可移动不可复制  
可以用std::move函数转移执行线程所有权  
如果线程已经管控一个执行线程，重复赋值会导致terminate函数
  
### 2.4 运行时选择线程数量
`std::thread::hardwareconcurrency`函数可以显示可并发的线程数量
  
### 2.5 识别线程
`std::thread::id`是线程id对象,可以使用get_id函数获得
  
## 3.线程间共享数据
**互斥**:`std::mutex`使用`lock()`加锁,`unlock()`释放锁，推荐使用`lock_guard`来存储锁资源  
避免向锁所在的作用域之外传递指向受保护的数据的指针和引用。  
**防范死锁**的建议是按相同顺序加锁，但是时间并不方便，可以使用`std::lock`函数锁住多个互斥锁，使用C++17中的`scoped_lock`更好，其是可变参数模板。但是不用锁也可能死锁，例如
```c++
void fun1()
{
    std::thread t1(fun2);
    t1.join();
}

void fun2()
{
    std::thread t2(fun1);
    t2.join();
}
```
防范死锁的方法:
1. 避免嵌套锁
2. 持锁后，避免调用由用户提供的接口
3. 按照固定顺序获取锁
4. 按层级加锁，对低优先级加锁过后不允许对高优先级加锁，强制规定顺序

**灵活使用std::unique_lock<>加锁**  
可传递第二参数`std::adopt_lock or std::defer_lock`来决定管理互斥或者直到成员函数lock被调用才加锁
  
**保护共享数据的其它工具**:`std::once_flag and std::call_once()`确保只被调用一次。
```c++
std::shared_ptr<some_resource> resource_ptr;
std::once_flag resource_flag;
void init();
void foo()
{
    std::call_once(resource_flag, init_resource);
    ...
}
```
在上述代码中确保初始化语句即使在多线程中也只被调用一次。在C++11后，静态局部变量被内置为线程安全的    
**保护较少更新的数据结构**:C++17提供`std::shared_mutex`和`std::shared_time_mutex`  
**递归加锁**:`std::recursive_mutex`，一般应用情景是函数之间互相调用，每一个都要锁
  
## 4.并发操作同步
### 4.1 等待事件发生--条件变量
如果要等待事件发生，有一些方式:
1. 自旋忙等
2. `std::this_thread::sleep_for()`函数使得线程入睡，放弃CPU
3. 使用条件变量

**条件变量**:`std::condition_variable`和`std::condition_variable_any` => header <condition_variable>.condition_variable优先使用，因为any更消耗资源，需要与mutex配合
```c++
std::condition_variable cond;
std::queue<int> data;
std::mutex mut;
std::unique_lock<std::mutex> lk(mut);
cond.wait(lk, []{return data.empty()});
cond.notify_one();
```
condition_variable本质是忙等的优化

### 4.2 使用future等待一次性事件
header => <future>  
主要接口=>`future`和`shared_future`和`std::ats::async()`  
future本身并不提供同步访问，多线程访问同一个future时需要保护  
**async函数**返回future对象，调用future成员函数get可以得到返回值，启动方式取默认值(`std::launch::deferred | std::launch::async`)，由系统自动决定。  
**关联future实例和任务：std::packaged_task<>** => std::packaged_task<>的模板参数是函数签名，是可调用对象，将运行结果保存在future中，通过get_future函数得到结果对象  
**创建std::promise**=>同样调用get_future函数得到future结果.在相关future数据阻塞时，可以用promise设定关联的值提供给future   

### 4.3 等待时间期限
超时机制有两种，一种是迟延超时(等待一定的时间)，一种是绝对超时(等待特定的时间点)前者API以_for为后缀，后者是_until  
时间类在`std::chrono`
### 4.4 运用同步操作简化代码
**利用future进行函数式编程**:
```c++
//并行版本的快速排序
template<typename T>
std::list<T> parallel_quick_sort(std::list<T> input)
{
	if (input.empty())
	{
		return input;
	}
	std::list<T> result;
	result.splice(result.begin(), input, input.begin());
	T const& pivot = *result.begin();
	auto divide_point = std::partition(input.begin(), input.end(),
		[&](T const& t) {return t < pivot; });
	std::list<T> lower_part;
	lower_part.splice(lower_part.end(), input, input.begin(),
		divide_point);
	// ①因为lower_part是副本，所以并行操作不会引发逻辑错误，这里可以启动future做排序
	std::future<std::list<T>> new_lower(
		std::async(&parallel_quick_sort<T>, std::move(lower_part)));
	
	// ②
	auto new_higher(
		parallel_quick_sort(std::move(input)));    
		result.splice(result.end(), new_higher);    
		result.splice(result.begin(), new_lower.get());    
		return result;
}

```

**CSP通信模型**:线程之间没有共享数据，完全依靠消息队列
**latch and barrier**:latch 和 barrier 对于线程同步机制来说很简单，它使一些线程能够等待直到计数器变为零。在 C++ 20 中，我们可能会得到三种变体的 latch 和barrier： std::latch, std::barrier，和std::flex_barrier 。
## 5. C++内存模型和原子操作
**C++内存模型**:每个变量都是对象，对象的数据成员也是对象。  
**原子操作**:header=><atomic>  
成员函数`is_lock_free()`返回原子操作是否是由硬件的原子指令实现或是内部互斥实现  
`std::atomic<>`特化有对应的别名  
**原子操作**:load(),store(),exchange(),compare_exchange_weak(),compare_exchange_strong()等被分为存储、载入、读-改-写三类  

**原子操作的非成员函数**：std::atomic_load，后缀加_explicit接收参数指定内存次序，甚至还支持`shared_ptr<>`的原子操作(shared_ptr事实上不是线程安全的)  
**同步操作和强制次序**:  
**内存序模型:**
1. 先后一致次序:memory_order_seq_cst  
2. 获取-释放次序:memory_order_consume, memory_order_acquire, memory_order_release, memory_order_acq_rel
3. 宽松次序:memory_order_relaxed  


**先后一致次序=memory_order_seq_cst**:操作保持前后一致顺序。编译器和CPU不得重排指令。也是默认次序。    
**宽松次序**:线程之间不存在次序关系，但是同一线程内对相同变量的访问次序不得重排  
```c++
std::atomic<bool> x,y;
std::atomic<int> z;
void write_x_and_y()
{
    x.load(true, std::memory_order_relaxed);
    y.load(true, std::memory_order_relaxed);
}
void read_y_then_x()
{
    while(!y.load(std::memory_order_relaxed));
    if(x.load(std::memory_order_relaxed))
        z++;
}
void main()
{
    x=false;
    y=false;
    z=0;
    std::thread a(write_x_and_y);
    std::thread b(read_y_then_x);
    a.join();
    b.join();
    assert(z.load()!=0); // 报错！
}
```
在宽松次序中，因为线程间没有次序，所以读取时请求值，可能跟上次一样，也可能比上次更新，但绝不会比上次更老的值。  
**获取-释放次序**:一定程度上的同步效果，但不会是一致的全局操作。原子化载入=>`memory_order_acquire`, 原子化存储=>`memory_order_release`, 两者皆是=>`memory_order_acq_rel`.用在成对的读写进程间同步。  
**memory_order_consume**：不推荐使用！完全针对数据依赖。
**栅栏(fence)**：限制指令的重新编排